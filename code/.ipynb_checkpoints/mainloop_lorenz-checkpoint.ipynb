{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910dc944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import pysindy as ps\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "from scipy.optimize import minimize\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenz(t, X, sigma=10, beta=8/3, rho=28):\n",
    "    x, y, z = X\n",
    "    dx = sigma * (y - x)\n",
    "    dy = x * (rho - z) - y\n",
    "    dz = x * y - beta * z\n",
    "    return [dx, dy, dz]\n",
    "\n",
    "def add_noise(data, percentage=0):\n",
    "    # additive white gaussian noise\n",
    "    noise_std = np.std(data) * (percentage / 100.0)\n",
    "    noise = np.random.normal(0, noise_std, data.shape)\n",
    "    return data + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4085aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def savgol_denoise_1D(data, window_length=11,poly_order=2):\n",
    "    denoised_data = savgol_filter(data, window_length, poly_order)  \n",
    "    return denoised_data\n",
    "\n",
    "def l1_trend_filter(y, lamb=0):\n",
    "    n = len(y)\n",
    "    x = cp.Variable(n)\n",
    "    # Construct the difference matrix D\n",
    "    D = np.diff(np.eye(n), axis=0)\n",
    "    D2 = np.diff(D,axis=0)\n",
    "    # Define the objective\n",
    "    objective = cp.Minimize(0.5 * cp.norm(x - y, 2)**2 + lamb * cp.norm(D2 @ x, 1))\n",
    "    # Solve the problem\n",
    "    problem = cp.Problem(objective)\n",
    "    \n",
    "    # Try using another solver\n",
    "    try:\n",
    "        problem.solve()\n",
    "    except cp.SolverError:\n",
    "        try:\n",
    "            problem.solve(solver=cp.SCS)\n",
    "        except cp.SolverError:\n",
    "            print(\"SCS also failed, trying another solver...\")\n",
    "            problem.solve(solver=cp.OSQP)\n",
    "    \n",
    "    return x.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee7596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenz_pareto_savgol_w(u_single):\n",
    "    windows = [i for i in range(5, 299, 2)]\n",
    "    solution_norms = []\n",
    "    residual_norms = []\n",
    "\n",
    "    for w in windows:\n",
    "        u_denoised = savgol_denoise_1D(u_single, w, 2)\n",
    "        residual = u_single - u_denoised\n",
    "        solution_norms.append(np.linalg.norm(u_denoised))\n",
    "        residual_norms.append(np.linalg.norm(residual))\n",
    "    \n",
    "    solution_norms = np.array(solution_norms)\n",
    "    residual_norms = np.array(residual_norms)\n",
    "    curvature = np.gradient(np.gradient(solution_norms, residual_norms), residual_norms)\n",
    "    max_curvature_idx = np.argmax(np.abs(curvature))\n",
    "    optimal_w = windows[max_curvature_idx]\n",
    "\n",
    "    return optimal_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f3b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenz_pareto_l1_lambda(u_single):\n",
    "    lambdas = np.logspace(-5, 2, 50)\n",
    "    solution_norms = []\n",
    "    residual_norms = []\n",
    "\n",
    "    for lambda_reg in lambdas:\n",
    "        # Apply L1 Trend Filter\n",
    "        u_denoised = l1_trend_filter(u_single, lambda_reg)\n",
    "        residual = u_single - u_denoised\n",
    "        solution_norms.append(np.linalg.norm(u_denoised))\n",
    "        residual_norms.append(np.linalg.norm(residual))\n",
    "\n",
    "    solution_norms = np.array(solution_norms)\n",
    "    residual_norms = np.array(residual_norms)\n",
    "    curvature = np.gradient(np.gradient(solution_norms, residual_norms), residual_norms)\n",
    "    max_curvature_idx = np.argmax(np.abs(curvature))\n",
    "    optimal_lambda = lambdas[max_curvature_idx]\n",
    "\n",
    "    return optimal_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e9401",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 500\n",
    "\n",
    "noise_levels = [0,5,10,15,20,25,30,35,40,45,50,55,60,65,70]\n",
    "\n",
    "true_coeffs_x = {'x': -10, 'y': 10}\n",
    "true_coeffs_y = {'x': 28, 'y': -1, 'xz': -1}\n",
    "true_coeffs_z = {'z': -2.666, 'xy': 1}\n",
    "threshold = 0.0005\n",
    "\n",
    "# Initialization\n",
    "dt = 0.001\n",
    "integrator_keywords = {}\n",
    "feature_names = ['x', 'y', 'z']\n",
    "\n",
    "t_train = np.arange(0, 8, dt)\n",
    "x0_train = [-8, 8, 27]\n",
    "t_train_span = (t_train[0], t_train[-1])\n",
    "x_train_original = solve_ivp(lorenz, t_train_span, x0_train, t_eval=t_train, **integrator_keywords).y.T\n",
    "\n",
    "for p in noise_levels: \n",
    "    \n",
    "    success_count = 0\n",
    "    success_count_savgol = 0\n",
    "    success_count_l1 = 0\n",
    "    success_count_savl1 = 0\n",
    "    success_count_l1sav = 0\n",
    "    \n",
    "    coeff_errors = []\n",
    "    coeff_errors_savgol = []\n",
    "    coeff_errors_l1 = []\n",
    "    coeff_errors_savl1 = []\n",
    "    coeff_errors_l1sav = []\n",
    "    \n",
    "    wrong_terms_list = []\n",
    "    wrong_terms_savgol_list = []\n",
    "    wrong_terms_l1_list = []\n",
    "    wrong_terms_savl1_list = []\n",
    "    wrong_terms_l1sav_list = []\n",
    "    \n",
    "    print(f\"Testing noise level: {p}\")\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "\n",
    "        x_train = add_noise(x_train_original, p)\n",
    "\n",
    "        library_functions = [lambda x: x, lambda x, y: x * y, lambda x: x ** 2]\n",
    "        library_function_names = [lambda x: x, lambda x, y: x + y, lambda x: x + x]\n",
    "\n",
    "        ode_lib = ps.WeakPDELibrary(library_functions=library_functions, \n",
    "                                function_names=library_function_names, \n",
    "                                spatiotemporal_grid=t_train, \n",
    "                                is_uniform = True,\n",
    "                                K=100,\n",
    "                                include_bias=False) #include a constant term in the library \n",
    "\n",
    "        x_dot_integral = ode_lib.convert_u_dot_integral(x_train)\n",
    "        \n",
    "        # weak form\n",
    "        model = ps.SINDy(feature_names=feature_names,\n",
    "                    optimizer=ps.STLSQ(),\n",
    "                    feature_library=ode_lib)\n",
    "        model.fit(x_train, x_dot=x_dot_integral,t=dt)\n",
    "        #print(\"no filter\")\n",
    "        #model.print()\n",
    "        coeffs = model.coefficients()\n",
    "\n",
    "        \n",
    "        \n",
    "        # filtering\n",
    "        \n",
    "        num_vars = x_train.shape[1]\n",
    "        \n",
    "        x_train_savgol = np.zeros_like(x_train)\n",
    "        x_train_l1 = np.zeros_like(x_train)\n",
    "        x_train_savl1 = np.zeros_like(x_train)\n",
    "        x_train_l1sav = np.zeros_like(x_train)\n",
    "        \n",
    "        for i in range(num_vars):\n",
    "            x_pareto_w = lorenz_pareto_savgol_w(x_train[:, i])\n",
    "            x_train_savgol[:, i] = savgol_denoise_1D(x_train[:, i], x_pareto_w, 2)\n",
    "            x_pareto_lambda = lorenz_pareto_l1_lambda(x_train[:, i])\n",
    "            x_train_l1[:, i] = l1_trend_filter(x_train[:, i], x_pareto_lambda)\n",
    "            \n",
    "        for i in range(num_vars):\n",
    "            savgol_pareto_lambda = lorenz_pareto_l1_lambda(x_train_savgol[:, i])\n",
    "            x_train_savl1[:, i] = l1_trend_filter(x_train_savgol[:, i], savgol_pareto_lambda)\n",
    "            l1_pareto_w = lorenz_pareto_savgol_w(x_train_l1[:, i])\n",
    "            x_train_l1sav[:, i] = savgol_denoise_1D(x_train_l1[:, i], l1_pareto_w, 2)\n",
    "\n",
    "        \n",
    "        # fitting weak filtered form\n",
    "        x_dot_integral_savgol = ode_lib.convert_u_dot_integral(x_train_savgol)    \n",
    "        x_dot_integral_l1 = ode_lib.convert_u_dot_integral(x_train_l1)    \n",
    "        x_dot_integral_savl1 = ode_lib.convert_u_dot_integral(x_train_savl1)  \n",
    "        x_dot_integral_l1sav = ode_lib.convert_u_dot_integral(x_train_l1sav)   \n",
    "\n",
    "        model_savgol = ps.SINDy(feature_names=feature_names,optimizer=ps.STLSQ(), feature_library=ode_lib) \n",
    "        model_savgol.fit(x_train_savgol, x_dot=x_dot_integral_savgol, t=dt)\n",
    "        coeffs_savgol = model_savgol.coefficients()\n",
    "        #print(\"savgol\")\n",
    "        #model_savgol.print()\n",
    "        model_l1 = ps.SINDy(feature_names=feature_names,optimizer=ps.STLSQ(), feature_library=ode_lib)\n",
    "        model_l1.fit(x_train_l1, x_dot=x_dot_integral_l1, t=dt)\n",
    "        coeffs_l1 = model_l1.coefficients()\n",
    "        #print(\"l1\")\n",
    "        #model_l1.print()\n",
    "        model_savl1 = ps.SINDy(feature_names=feature_names,optimizer=ps.STLSQ(), feature_library=ode_lib)\n",
    "        model_savl1.fit(x_train_savl1, x_dot=x_dot_integral_savl1, t=dt)\n",
    "        coeffs_savl1 = model_savl1.coefficients()\n",
    "        #print(\"savl1\")\n",
    "        #model_savl1.print()\n",
    "        model_l1sav = ps.SINDy(feature_names=feature_names,optimizer=ps.STLSQ(), feature_library=ode_lib)\n",
    "        model_l1sav.fit(x_train_l1sav, x_dot=x_dot_integral_l1sav, t=dt)\n",
    "        coeffs_l1sav = model_l1sav.coefficients()\n",
    "        #print(\"l1sav\")\n",
    "        #model_l1sav.print()\n",
    "        \n",
    "        \n",
    "        timesteps = np.arange(x_train.shape[0])\n",
    "        labels = ['x', 'y', 'z']\n",
    "\n",
    "        all_terms = model.get_feature_names()\n",
    "        # Desired terms as per given equations\n",
    "        desired_terms_x = set(['x', 'y'])\n",
    "        desired_terms_y = set(['x', 'y', 'xz'])\n",
    "        desired_terms_z = set(['z', 'xy'])\n",
    "\n",
    "        # Function to get active terms for an equation\n",
    "        def get_active_terms(coeff_row, all_terms):\n",
    "            return set([term for idx, term in enumerate(all_terms) if abs(coeff_row[idx]) > threshold])\n",
    "\n",
    "        # Extract active terms\n",
    "        active_terms_x = get_active_terms(coeffs[0], all_terms)\n",
    "        active_terms_y = get_active_terms(coeffs[1], all_terms)\n",
    "        active_terms_z = get_active_terms(coeffs[2], all_terms)\n",
    "        \n",
    "        active_terms_x_savgol = get_active_terms(coeffs_savgol[0], all_terms)\n",
    "        active_terms_y_savgol = get_active_terms(coeffs_savgol[1], all_terms)\n",
    "        active_terms_z_savgol = get_active_terms(coeffs_savgol[2], all_terms)\n",
    "        \n",
    "        active_terms_x_l1 = get_active_terms(coeffs_l1[0], all_terms)\n",
    "        active_terms_y_l1 = get_active_terms(coeffs_l1[1], all_terms)\n",
    "        active_terms_z_l1 = get_active_terms(coeffs_l1[2], all_terms)\n",
    "        \n",
    "        active_terms_x_savl1 = get_active_terms(coeffs_savl1[0], all_terms)\n",
    "        active_terms_y_savl1 = get_active_terms(coeffs_savl1[1], all_terms)\n",
    "        active_terms_z_savl1 = get_active_terms(coeffs_savl1[2], all_terms)\n",
    "        \n",
    "        active_terms_x_l1sav = get_active_terms(coeffs_l1sav[0], all_terms)\n",
    "        active_terms_y_l1sav = get_active_terms(coeffs_l1sav[1], all_terms)\n",
    "        active_terms_z_l1sav = get_active_terms(coeffs_l1sav[2], all_terms)\n",
    "        \n",
    "        \n",
    "        # Check for exact match\n",
    "        if active_terms_x == desired_terms_x and active_terms_y == desired_terms_y and active_terms_z == desired_terms_z:\n",
    "            success_count += 1\n",
    "            \n",
    "        if (active_terms_x_savgol == desired_terms_x and \n",
    "            active_terms_y_savgol == desired_terms_y and \n",
    "            active_terms_z_savgol == desired_terms_z):\n",
    "            success_count_savgol += 1\n",
    "            \n",
    "        if (active_terms_x_l1 == desired_terms_x and \n",
    "            active_terms_y_l1 == desired_terms_y and \n",
    "            active_terms_z_l1 == desired_terms_z):\n",
    "            success_count_l1 += 1\n",
    "            \n",
    "        if (active_terms_x_savl1 == desired_terms_x and \n",
    "            active_terms_y_savl1 == desired_terms_y and \n",
    "            active_terms_z_savl1 == desired_terms_z):\n",
    "            success_count_savl1 += 1\n",
    "            \n",
    "        if (active_terms_x_l1sav == desired_terms_x and \n",
    "            active_terms_y_l1sav == desired_terms_y and \n",
    "            active_terms_z_l1sav == desired_terms_z):\n",
    "            success_count_l1sav += 1\n",
    "            \n",
    "        \n",
    "        # Coeff errors\n",
    "        coeff_error = 0\n",
    "        coeff_error_savgol = 0\n",
    "        coeff_error_l1 = 0\n",
    "        coeff_error_savl1 = 0\n",
    "        coeff_error_l1sav = 0\n",
    "        for term in desired_terms_x: \n",
    "            idx = all_terms.index(term)\n",
    "            coeff_error += abs(coeffs[0, idx] - true_coeffs_x[term])\n",
    "            coeff_error_savgol += abs(coeffs_savgol[0, idx] - true_coeffs_x[term])\n",
    "            coeff_error_l1 += abs(coeffs_l1[0, idx] - true_coeffs_x[term])\n",
    "            coeff_error_savl1 += abs(coeffs_savl1[0, idx] - true_coeffs_x[term])\n",
    "            coeff_error_l1sav += abs(coeffs_l1sav[0, idx] - true_coeffs_x[term])\n",
    "        for term in desired_terms_y: \n",
    "            idx = all_terms.index(term)\n",
    "            coeff_error += abs(coeffs[1, idx] - true_coeffs_y[term])\n",
    "            coeff_error_savgol += abs(coeffs_savgol[1, idx] - true_coeffs_y[term])\n",
    "            coeff_error_l1 += abs(coeffs_l1[1, idx] - true_coeffs_y[term])\n",
    "            coeff_error_savl1 += abs(coeffs_savl1[1, idx] - true_coeffs_y[term])\n",
    "            coeff_error_l1sav += abs(coeffs_l1sav[1, idx] - true_coeffs_y[term])\n",
    "        for term in desired_terms_z: \n",
    "            idx = all_terms.index(term)\n",
    "            coeff_error += abs(coeffs[2, idx] - true_coeffs_z[term])\n",
    "            coeff_error_savgol += abs(coeffs_savgol[2, idx] - true_coeffs_z[term])\n",
    "            coeff_error_l1 += abs(coeffs_l1[2, idx] - true_coeffs_z[term])\n",
    "            coeff_error_savl1 += abs(coeffs_savl1[2, idx] - true_coeffs_z[term])\n",
    "            coeff_error_l1sav += abs(coeffs_l1sav[2, idx] - true_coeffs_z[term])\n",
    "            \n",
    "        coeff_errors.append(coeff_error)\n",
    "        coeff_errors_savgol.append(coeff_error_savgol)\n",
    "        coeff_errors_l1.append(coeff_error_l1)\n",
    "        coeff_errors_savl1.append(coeff_error_savl1)\n",
    "        coeff_errors_l1sav.append(coeff_error_l1sav)\n",
    "        \n",
    "        \n",
    "        # Wrong terms count\n",
    "        wrong_terms = 0\n",
    "        wrong_terms += len([term for term in active_terms_x if term not in desired_terms_x])\n",
    "        wrong_terms += len([term for term in active_terms_y if term not in desired_terms_y])\n",
    "        wrong_terms += len([term for term in active_terms_z if term not in desired_terms_z])\n",
    "        wrong_terms_savgol= 0\n",
    "        wrong_terms_savgol += len([term for term in active_terms_x_savgol if term not in desired_terms_x])\n",
    "        wrong_terms_savgol += len([term for term in active_terms_y_savgol if term not in desired_terms_y])\n",
    "        wrong_terms_savgol += len([term for term in active_terms_z_savgol if term not in desired_terms_z])\n",
    "        wrong_terms_l1 = 0\n",
    "        wrong_terms_l1 += len([term for term in active_terms_x_l1 if term not in desired_terms_x])\n",
    "        wrong_terms_l1 += len([term for term in active_terms_y_l1 if term not in desired_terms_y])\n",
    "        wrong_terms_l1 += len([term for term in active_terms_z_l1 if term not in desired_terms_z])\n",
    "        wrong_terms_savl1 = 0\n",
    "        wrong_terms_savl1 += len([term for term in active_terms_x_savl1 if term not in desired_terms_x])\n",
    "        wrong_terms_savl1 += len([term for term in active_terms_y_savl1 if term not in desired_terms_y])\n",
    "        wrong_terms_savl1 += len([term for term in active_terms_z_savl1 if term not in desired_terms_z])\n",
    "        wrong_terms_l1sav = 0\n",
    "        wrong_terms_l1sav += len([term for term in active_terms_x_l1sav if term not in desired_terms_x])\n",
    "        wrong_terms_l1sav += len([term for term in active_terms_y_l1sav if term not in desired_terms_y])\n",
    "        wrong_terms_l1sav += len([term for term in active_terms_z_l1sav if term not in desired_terms_z])\n",
    "\n",
    "        wrong_terms_list.append(wrong_terms)\n",
    "        wrong_terms_savgol_list.append(wrong_terms_savgol)\n",
    "        wrong_terms_l1_list.append(wrong_terms_l1)\n",
    "        wrong_terms_savl1_list.append(wrong_terms_savl1)\n",
    "        wrong_terms_l1sav_list.append(wrong_terms_l1sav)\n",
    "        \n",
    "        \n",
    "    # Success rate\n",
    "    success_rate = (success_count / num_iterations) * 100\n",
    "    success_rate_savgol = (success_count_savgol / num_iterations) * 100\n",
    "    success_rate_l1 = (success_count_l1 / num_iterations) * 100\n",
    "    success_rate_savl1 = (success_count_savl1 / num_iterations) * 100\n",
    "    success_rate_l1sav = (success_count_l1sav / num_iterations) * 100\n",
    "    print(f\"Success rate using original data: {success_rate}%\")\n",
    "    print(f\"Success rate using savgol data: {success_rate_savgol}%\")\n",
    "    print(f\"Success rate using l1 data: {success_rate_l1}%\")\n",
    "    print(f\"Success rate using savl1 data: {success_rate_savl1}%\")\n",
    "    print(f\"Success rate using l1sav data: {success_rate_l1sav}%\")\n",
    "    \n",
    "    print(f\"Average coefficient error using original data: {np.mean(coeff_errors)} ± {np.std(coeff_errors)}\")\n",
    "    print(f\"Average coefficient error using savgol data: {np.mean(coeff_errors_savgol)} ± {np.std(coeff_errors_savgol)}\")\n",
    "    print(f\"Average coefficient error using l1 data: {np.mean(coeff_errors_l1)} ± {np.std(coeff_errors_l1)}\")\n",
    "    print(f\"Average coefficient error using savl1 data: {np.mean(coeff_errors_savl1)} ± {np.std(coeff_errors_savl1)}\")\n",
    "    print(f\"Average coefficient error using l1sav data: {np.mean(coeff_errors_l1sav)} ± {np.std(coeff_errors_l1sav)}\")\n",
    "                                                                                          \n",
    "    print(f\"Average number of wrong terms using original data: {np.mean(wrong_terms_list)} ± {np.std(wrong_terms_list)}\")\n",
    "    print(f\"Average number of wrong terms using savgol data: {np.mean(wrong_terms_savgol_list)} ± {np.std(wrong_terms_savgol_list)}\")\n",
    "    print(f\"Average number of wrong terms using l1 data: {np.mean(wrong_terms_l1_list)} ± {np.std(wrong_terms_l1_list)}\")\n",
    "    print(f\"Average number of wrong terms using savl1 data: {np.mean(wrong_terms_savl1_list)} ± {np.std(wrong_terms_savl1_list)}\")                     \n",
    "    print(f\"Average number of wrong terms using l1sav data: {np.mean(wrong_terms_l1sav_list)} ± {np.std(wrong_terms_l1sav_list)}\")                                                                                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
